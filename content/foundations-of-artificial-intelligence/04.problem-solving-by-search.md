---
title: "Chapter 3: Problem Solving by Search"
description: "Search algorithms for problem solving, including uninformed and informed search strategies, heuristics, and algorithm comparisons"
authors:
  - "Andrea Lunghi"
  - "Niccol√≤ Papini"
slug: "problem-solving-by-search"
---

When an agent plans ahead to find a sequence of action that lead to a goal, it is called **Search**.

There are four main phases of a search problem:

- **Goal Formulation**: The agent decides what it wants to achieve. This help organize behaviors, limiting objectives, and actions to consider.
- **Problem Formulation**: The agent needs a description of the rules of the environment.
- **Search**: The agent looks for a sequence of actions that lead to the goal.
- **Execution**: The agent executes the plan.

When the environment is _fully-observable_, _deterministic_, and _known_, the solution is fixed and we can ignore the _perception_. This is called **Open-Loop**.
Otherwise, we need to consider the _perception_ during the _execution_ of the plan. This is called **Closed-Loop**.

A **Problem** is defined by:

- **Initial State**: The state, or configuration, where the agent starts.
- **Goal(s) state**: The state, or configuration, where the agent wants to go. Can be a set of states or a function.
- **Actions**: A function that given a state, return a set of actions that the agent can perform.
- **Transition Model**: A function that given a state and an action, return the next state.
- **Action Cost**: A function that given a state and an action, return the cost of that action.

A sequence of action is called a **Path**. If a path starts from the initial state and ends in a goal state, it is called a **Solution**.
If that solution has the lowest cost among all the possible solutions, it is called an **Optimal Solution**.

We can represent the problem as a **State Space Graph**, where the nodes are the states and the edges are the actions.

We want to find a solution without building the entire graph, because it could be too large. We want to _partially build_ the graph while searching for the solution.
To do that we use a **Search Algorithm**.

## 3.1 Search Algorithm

A search algorithm is based on a **Search Tree** to represent the search space. The root of the tree is the initial state, each node is a state and the branches are the actions.

The difference between a search-tree and the graph-space is that: the graph describes all the possible states and actions, while the tree describes the states and actions that the agent has already explored, creating paths from the initial state to each explored node.

The search algorithm has two main components:

- **Frontier**: The set of nodes that the agent has to explore.
- **Explored Set**: The set of nodes that the agent has already explored.

When we _explore_ a node, we add it to the explored set and remove it from the frontier. Then we _expand_ the node, generating the children nodes, and add them to the frontier.

### 3.1.1 Best-First Search

This type of algorithms each node is evaluated based on a **Evaluation Function** ($f(n)$).

On each iteration we choose a node with the minimum $f(n)$ cost from the frontier and, if it isn't the goal, we expand it.

If a repeated state is reached, its expansion would generate an infinite cycle. To avoid this we can:

- Store all previously visited states, avoiding redundant paths.
- Check the current path to avoid cycles. This approach doesn't avoid redundant paths.
- If it's impossible to reach the same state, we can ignore the repeated state.

When we search for redundant paths, the algorithm is called **Graph Search**.

### 3.1.2 Data Structure

Each node is made by four main components:

- **State**: The state of the node.
- **Parent**: The node that generated this node. Following the parent we can reconstruct the path.
- **Action**: The action that generated this node.
- **Path Cost**: The cost of the path from the initial state to this node.

The way that the frontier is implemented change the behavior of the algorithm.

- **Priority Queue**: The frontier is ordered based on the evaluation function and the node with the lowest cost is expanded first.
- **Queue** (FIFO): The frontier is a queue and the node that is added first is expanded first.
- **Stack** (LIFO): The frontier is a stack and the node that is added last is expanded first.

### 3.1.3 Algorithm Evaluation

The performance of a search algorithm can be evaluated based on:

- **Completeness**: The algorithm finds a solution if one exists.
- **Optimality**: The algorithm finds the optimal solution.
- **Time Complexity**: The number of nodes generated by the algorithm.
- **Space Complexity**: The maximum number of nodes stored in memory.

The complexity is measured in terms of:

- **Depth** ($d$): The depth of the shallowest solution.
- **Branching Factor** ($b$): The number of children of each node.
- **Maximum Depth** ($m$): The maximum depth of the search tree.
- **Optimal Solution** ($C^*$): The cost of the optimal solution.
- **Smaller cost-action** ($\epsilon$): The cost of the action.

## 3.2 Uninformed Search

An **Uninformed Search** is a category of search algorithms that has no information about how close a state is to the goal.

### 3.2.1 Breadth-First Search

This algorithm expands the shallowest node first and it's good when all actions have the same cost.

We can implement this using:

- **Evaluation Function**: $f(n) = \text{depth}(n)$
- **Frontier**: Queue, because the shallowest node is the one that has been added first.

This algorithm allows to find the solution with the minimum amount of actions for each node. This allows to perform an _Early Goal Test_, which is a test that checks if a generated node is a goal before expanding it.
A _Late Goal Test_ is a test that checks if a popped node is a goal before expanding it.

#### Breadth-First Performance

On each level of the tree, the algorithm generates $b^n$ nodes, where $b$ is the branching factor and $n$ is the depth of the tree.

- **Completeness**: The algorithm is complete if the branching factor is finite.
- **Optimality**: The algorithm is optimal if the cost of the actions is the same.
- **Time Complexity**: $O(b^d)$
- **Space Complexity**: $O(b^d)$

### 3.2.2 Uniform-Cost Search

This algorithm expands the node with the lowest path cost. This is also called **Dijkstra's Algorithm**.

We can implement this using:

- **Evaluation Function**: $f(n) = \text{path-cost}(n)$
- **Frontier**: Priority Queue

#### Uniform-Cost Performance

The complexity is based on the cost of the optimal solution and the cost of the actions.
The algorithm might explore trees with a low cost before exploring trees with a high cost, but more useful.

- **Completeness**: The algorithm is complete if the cost of the actions is finite.
- **Optimality**: The algorithm is optimal.
- **Time Complexity**: $O(b^{1+\lfloor C^*/\epsilon \rfloor})$
- **Space Complexity**: $O(b^{1+\lfloor C^*/\epsilon \rfloor})$

### 3.2.3 Depth-First Search

This algorithm expands the deepest node first and it's good when the solution is far from the initial state.

This can be implemented using:

- **Evaluation Function**: $f(n) = -\text{depth}(n)$
- **Frontier**: Stack, because the deepest node is the one that has been added last.

This algorithm is usually implemented as a tree-search instead of a graph-search.

#### Depth-First Performance

The advantage of this algorithm is that it doesn't need much memory. There is no need to store a reached table, and the frontier is small.

- **Completeness**: The algorithm is not complete if the tree is infinite.
- **Optimality**: The algorithm is not optimal because it return the first solution found.
- **Time Complexity**: $O(b^m)$
- **Space Complexity**: $O(bm)$

### 3.2.4 Backtracking Search

This is a variant of the depth-first search that doesn't generate all the successors of a node. Instead, it generates a successor and, if it doesn't lead to a solution, it generates the next one.

This algorithm can reduce the memory requirements to just a single state and a list of actions. This allow to modify the current state instead of creating a new one.

It's necessary to undo the changes made to the state when backtracking.

#### Backtracking Performance

- **Completeness**: The algorithm is complete if the tree is finite.
- **Optimality**: The algorithm is not optimal.
- **Time Complexity**: $O(b^m)$
- **Space Complexity**: $O(m)$

### 3.2.5 Depth-Limited Search

This is a variant of the depth-first search that limits the search to a specific depth ($l$) of the tree. This is useful when the tree is infinite.

If the depth limit is less than the depth of the solution, the algorithm'll never find the solution.
This is not a problem if we know the maximum depth that the tree can reach or the _Diameter_ (the minimum amount of actions to reach each state).

#### Depth-Limited Performance

- **Completeness**: The algorithm is not complete if the depth limit is less than the depth of the solution.
- **Optimality**: The algorithm is not optimal.
- **Time Complexity**: $O(b^l)$
- **Space Complexity**: $O(bl)$

### 3.2.6 Iterative Deepening Search

This is a variant of the depth-limited search that iteratively increases the depth limit until a solution is found.

#### Iterative Deepening Performance

This algorithm might seem inefficient because it explores the same nodes multiple times, but most of the nodes are at the bottom of the tree, so it's complexity is asymptotical to the breadth-first search.

- **Completeness**: The algorithm is complete.
- **Optimality**: The algorithm is optimal if the cost of the actions is the same.
- **Time Complexity**: $O(b^d)$ if there is a solution, $O(b^m)$ if there isn't.
- **Space Complexity**: $O(bd)$

### 3.2.7 Bidirectional Search

This algorithm starts from the initial state and the goal state and expands both until they meet in the middle.

This algorithm needs to store two frontiers and two explored state table.

This algorithm can be implemented using any search algorithm, but it's usually implemented using the breadth-first search.

#### Bidirectional Performance

- **Completeness**: The algorithm is complete if the branching factor is finite.
- **Optimality**: The algorithm is optimal if the cost of the actions is the same.
- **Time Complexity**: $O(b^{d/2})$
- **Space Complexity**: $O(b^{d/2})$

### 3.2.8 Comparison

| Algorithm                  | Completeness | Optimality | Time Complexity                         | Space Complexity                        |
| -------------------------- | ------------ | ---------- | --------------------------------------- | --------------------------------------- |
| Breadth-First Search       | Yes          | Yes        | $O(b^d)$                                | $O(b^d)$                                |
| Uniform-Cost Search        | Yes          | Yes        | $O(b^{1+\lfloor C^*/\epsilon \rfloor})$ | $O(b^{1+\lfloor C^*/\epsilon \rfloor})$ |
| Depth-First Search         | No           | No         | $O(b^m)$                                | $O(bm)$                                 |
| Backtracking Search        | Yes          | No         | $O(b^m)$                                | $O(m)$                                  |
| Depth-Limited Search       | No           | No         | $O(b^l)$                                | $O(bl)$                                 |
| Iterative Deepening Search | Yes          | Yes        | $O(b^d)$                                | $O(bd)$                                 |
| Bidirectional Search       | Yes          | Yes        | $O(b^{d/2})$                            | $O(b^{d/2})$                            |

## 3.3 Informed Search

Informed search strategies use domain specific information about the problem to guide the search toward the goal.
To achieve this, we use a **Heuristic Function** ($h(n)$), which estimates the cost of the cheapest path from the state at node $n$ to a goal state.

### 3.3.1 Heuristic Function

An heuristic function can be implemented in different ways.

To measure the quality of an heuristic function we can use the **Effective Branching Factor** ($b^*$), which is the average number of nodes generated by the algorithm.

$$N+1 = \sum_{i=0}^d (b^*)^1$$

Where $N$ is the number of nodes generated by the algorithm.

More accurate heuristic functions have a lower effective branching factor.

### 3.3.2 Greedy Best-First Search

This algorithm expands the node that is closest to the goal, based on the heuristic function.

We can implement this using:

- **Evaluation Function**: $f(n) = h(n)$
- **Frontier**: Priority Queue

This algorithm is not optimal because it doesn't consider the cost of the path and only try to reach the goal as fast as possible.

#### Greedy Best-First Performance

- **Completeness**: The algorithm is not complete.
- **Optimality**: The algorithm is not optimal.
- **Time Complexity**: $O(b^m)$
- **Space Complexity**: $O(b^m)$

### 3.3.3 A\* Search

This algorithm expands the node with the lowest $f(n)$ cost, where $f(n) = g(n) + h(n)$, $g(n)$ is the cost of the path from the initial state to node $n$ and $h(n)$ is the heuristic function.

We can implement this using:

- **Evaluation Function**: $f(n) = g(n) + h(n)$
- **Frontier**: Priority Queue

The heuristic function must be **admissible**, which means that it never overestimates the cost of reaching the goal.
Or it should be **consistent**, which means that the cost of reaching the goal from node $n$ is less than or equal to the cost of reaching the goal from node $n$ plus the cost of reaching the next node.

$$h(n) \leq h(n') + c(n, a, n')$$

A\* only expands nodes that have a lower cost than the cost of the optimal solution. This allow to **prune** the search tree, reducing the number of nodes generated.

#### A\* Performance

- **Completeness**: The algorithm is complete.
- **Optimality**: The algorithm is optimal if the heuristic function is admissible.
- **Time Complexity**: $O(b^d)$
- **Space Complexity**: $O(b^d)$

### 3.3.4 Weighted A\* Search

A\* has the problem that the heuristic function can be too optimistic, leading to a large number of nodes generated.

One way to solve this is to use a **Weighted A\***, which multiplies the heuristic function by a weight $w$ ($w > 1$).

$$f(n) = g(n) + w \cdot h(n)$$

This introduce an inadmissible heuristic function, but it can be useful to reduce the number of nodes generated.

Based on the weight we can have different algorithms:

| Weight           | Evaluation function          | Algorithm                |
| ---------------- | ---------------------------- | ------------------------ |
| $w = 0$          | $f(n) = g(n)$                | Uniform-cost search      |
| $w = 1$          | $f(n) = g(n) + h(n)$         | A\* search               |
| $1 < w < \infin$ | $f(n) = g(n) + w \cdot h(n)$ | Weighted A\* search      |
| $w = \infin$     | $f(n) = h(n)$                | Greedy best-first search |

#### Weighted A\* Performance

- **Completeness**: The algorithm is complete.
- **Optimality**: The algorithm is suboptimal.
- **Time Complexity**: $O(b^d)$
- **Space Complexity**: $O(b^d)$

### 3.3.5 Iterative Deepening A\* Search

This algorithm is a variant of the A*search that introduces a*cutoff\* value. This value is the maximum cost of the path that the algorithm can explore.

If the algorithm reaches the cutoff value, it restarts and increases the cutoff value to the smallest evaluation of non-expanded nodes.

#### Iterative Deepening A\* Performance

This algorithm is efficient memory-wise, but it can be slow because it explores the same nodes multiple times.

- **Completeness**: The algorithm is complete.
- **Optimality**: The algorithm is optimal if the heuristic function is admissible.
- **Time Complexity**: $O(b^d)$
- **Space Complexity**: $O(b^d)$

### 3.3.6 Bidirectional heuristic search

This algorithm is a variant of the bidirectional search that uses the heuristic function to guide the search.

With this configuration there are two heuristic functions, one for the starting from initial state (forward) and one for the one starting from goal state (backward).

- **Forward**: $f_f(n) = g_f(n) + h_f(n)$
- **Backward**: $f_b(n) = g_b(n) + h_b(n)$

One problem with this algorithm is that we don't know which is the best node to expand between the two frontiers.

#### Bidirectional heuristic search Performance

- **Completeness**: The algorithm is complete.
- **Optimality**: The algorithm is optimal if the heuristic function is admissible.
- **Time Complexity**: $O(b^{d/2})$
- **Space Complexity**: $O(b^{d/2})$

### 3.3.7 Comparison

| Algorithm                      | Completeness | Optimality | Time Complexity | Space Complexity |
| ------------------------------ | ------------ | ---------- | --------------- | ---------------- |
| Greedy Best-First Search       | No           | No         | $O(b^m)$        | $O(b^m)$         |
| A\* Search                     | Yes          | Yes        | $O(b^d)$        | $O(b^d)$         |
| Weighted A\* Search            | Yes          | No         | $O(b^d)$        | $O(b^d)$         |
| Bidirectional heuristic search | Yes          | Yes        | $O(b^{d/2})$    | $O(b^{d/2})$     |
